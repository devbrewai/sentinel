{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3925000",
   "metadata": {},
   "source": [
    "# Sanctions Screening Evaluation\n",
    "\n",
    "- **Purpose:** Evaluate sanctions screening accuracy and validate precision/recall targets\n",
    "- **Author:** Devbrew LLC  \n",
    "- **Last Updated:** November 17, 2025  \n",
    "- **Status:** In progress  \n",
    "- **License:** Apache 2.0\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook implements the evaluation protocol for the sanctions screening module. The evaluation measures matching accuracy through a labeled test set and validates that the system meets production accuracy targets.\n",
    "\n",
    "**Evaluation Metrics:**\n",
    "- Precision@1: Percentage of queries where top candidate is the correct match (target: ≥95%)\n",
    "- Recall@top3: Percentage of queries where ground truth match appears in top 3 (target: ≥98%)\n",
    "- False Positive Rate: Percentage of non-matches incorrectly flagged as matches\n",
    "- Decision Accuracy: Alignment between predicted and expected decision categories\n",
    "\n",
    "The evaluation validates that the screening system correctly identifies sanctioned entities while minimizing false positives, meeting production readiness requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cd7cc8",
   "metadata": {},
   "source": [
    "## Setup: Artifacts and Functions\n",
    "\n",
    "The evaluation loads artifacts generated by the implementation pipeline:\n",
    "\n",
    "- **Sanctions Index**: Canonicalized names and metadata (`sanctions_index.parquet`)\n",
    "- **Blocking Indices**: Inverted indices for candidate retrieval (`blocking_indices.json`)\n",
    "- **Metadata**: Version tracking and dataset statistics\n",
    "\n",
    "Helper functions for text normalization, tokenization, and screening are loaded to enable independent evaluation runs without re-executing the full implementation pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9ea27b",
   "metadata": {},
   "source": [
    "### Environment Configuration\n",
    "\n",
    "We configure the Python environment with standardized settings, import required libraries, and set a fixed random seed for reproducibility. This ensures consistent evaluation results across runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "716a07d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment configured successfully\n",
      " pandas: 2.3.3\n",
      " numpy: 2.3.3\n",
      " rapidfuzz: 3.14.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import json\n",
    "import unicodedata\n",
    "import re\n",
    "from typing import Dict, Any, Optional, List, Tuple\n",
    "import time\n",
    "import random\n",
    "from functools import lru_cache\n",
    "from collections import OrderedDict\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import rapidfuzz as rf\n",
    "from rapidfuzz import fuzz, process\n",
    "\n",
    "# Configuration\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "pd.set_option(\"display.float_format\", '{:.2f}'.format)\n",
    "\n",
    "# Reproducibility\n",
    "RANDOM_STATE = 42\n",
    "random.seed(RANDOM_STATE)\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "print(\"Environment configured successfully\")\n",
    "print(f\" pandas: {pd.__version__}\")\n",
    "print(f\" numpy: {np.__version__}\")\n",
    "print(f\" rapidfuzz: {rf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c53e45",
   "metadata": {},
   "source": [
    "### Load Artifacts\n",
    "\n",
    "The evaluation loads pre-computed artifacts from the implementation pipeline. The sanctions index contains 39,350 canonicalized name records with metadata. Blocking indices enable O(1) candidate retrieval through inverted index lookups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "213466b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading artifacts...\n",
      "\n",
      "Loaded sanctions index: 39,350 records\n",
      "Loaded blocking indices:\n",
      " - First token index: 15,597 keys\n",
      " - Bucket index: 4 keys\n",
      " - Initials index: 15,986 keys\n",
      "\n",
      "Loaded metadata: version 2025-11-17T06:00:56.218723\n",
      "\n",
      "All artifacts loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Path configuration\n",
    "PROJECT_ROOT = Path.cwd().parent if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "MODELS_DIR = PROJECT_ROOT / \"packages\" / \"models\"\n",
    "DATA_DIR = PROJECT_ROOT / \"data_catalog\" / \"processed\"\n",
    "\n",
    "\n",
    "print(\"Loading artifacts...\\n\")\n",
    "\n",
    "# Load sanctions index\n",
    "sanctions_index_path = MODELS_DIR / \"sanctions_index.parquet\"\n",
    "if not sanctions_index_path.exists():\n",
    "    raise FileNotFoundError(f\"Sanctions index not found: {sanctions_index_path}\\n\"\n",
    "                          f\"Please run notebooks/04_sanctions_screening.ipynb first to generate artifacts.\")\n",
    "\n",
    "sanctions_index = pd.read_parquet(sanctions_index_path)\n",
    "print(f\"Loaded sanctions index: {len(sanctions_index):,} records\")\n",
    "\n",
    "# Load blocking indices\n",
    "blocking_indices_path = MODELS_DIR / \"blocking_indices.json\"\n",
    "if not blocking_indices_path.exists():\n",
    "    raise FileNotFoundError(f\"Blocking indices not found: {blocking_indices_path}\\n\"\n",
    "                          f\"Please run notebooks/04_sanctions_screening.ipynb first to generate artifacts.\")\n",
    "\n",
    "with open(blocking_indices_path, 'r') as f:\n",
    "    blocking_indices = json.load(f)\n",
    "\n",
    "first_token_index = {k: v for k, v in blocking_indices['first_token'].items()}\n",
    "bucket_index = {k: v for k, v in blocking_indices['bucket'].items()}\n",
    "initials_index = {k: v for k, v in blocking_indices['initials'].items()}\n",
    "\n",
    "print(f\"Loaded blocking indices:\")\n",
    "print(f\" - First token index: {len(first_token_index):,} keys\")\n",
    "print(f\" - Bucket index: {len(bucket_index):,} keys\")\n",
    "print(f\" - Initials index: {len(initials_index):,} keys\")\n",
    "\n",
    "# Load metadata (optional, for version tracking)\n",
    "metadata_path = MODELS_DIR / \"sanctions_index_metadata.json\"\n",
    "if metadata_path.exists():\n",
    "    with open(metadata_path, 'r') as f:\n",
    "        sanctions_index_metadata = json.load(f)\n",
    "    print(f\"\\nLoaded metadata: version {sanctions_index_metadata.get('created_at', 'unknown')}\")\n",
    "else:\n",
    "    sanctions_index_metadata = {}\n",
    "    print(\"[Warning] Metadata not found (optional)\")\n",
    "\n",
    "print(f\"\\nAll artifacts loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad19a28",
   "metadata": {},
   "source": [
    "### Helper Functions\n",
    "\n",
    "Text normalization and tokenization functions are imported from the shared `packages.compliance.sanctions` module. This module provides standardized functions used by both `04_sanctions_screening.ipynb` and this evaluation notebook, ensuring consistency across the screening pipeline.\n",
    "\n",
    "The shared functions include:\n",
    "- `normalize_text()`: Text normalization for robust fuzzy matching\n",
    "- `tokenize()`: Tokenization with stopword filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02a7cb7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions imported successfully\n",
      "  - normalize_text: normalize_text\n",
      "  - tokenize: tokenize\n"
     ]
    }
   ],
   "source": [
    "from packages.compliance.sanctions import (\n",
    "    normalize_text,\n",
    "    tokenize\n",
    ")\n",
    "\n",
    "# Verify imports work\n",
    "print(\"Helper functions imported successfully\")\n",
    "print(f\"  - normalize_text: {normalize_text.__name__}\")\n",
    "print(f\"  - tokenize: {tokenize.__name__}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (devbrew-payments-fraud-sanctions)",
   "language": "python",
   "name": "devbrew-payments-fraud-sanctions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
